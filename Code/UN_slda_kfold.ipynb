{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "des_path = \"UN_kfold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>country_name</th>\n",
       "      <th>coalition_of_willing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>PAN</td>\n",
       "      <td>﻿Allow me\\nto begin my statement by expressing...</td>\n",
       "      <td>135</td>\n",
       "      <td>﻿allow me\\nto begin my statement by expressing...</td>\n",
       "      <td>Panama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>IND</td>\n",
       "      <td>﻿I\\ncongratulate Mr. Kavan on his election as ...</td>\n",
       "      <td>77</td>\n",
       "      <td>﻿i\\ncongratulate mr kavan on his election as p...</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>MDV</td>\n",
       "      <td>﻿Mr. President, it gives\\nme great pleasure to...</td>\n",
       "      <td>110</td>\n",
       "      <td>﻿mr president it gives\\nme great pleasure to j...</td>\n",
       "      <td>Maldives</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>DJI</td>\n",
       "      <td>﻿In a year\\nof frightful tragedy and uncertain...</td>\n",
       "      <td>45</td>\n",
       "      <td>﻿in a year\\nof frightful tragedy and uncertain...</td>\n",
       "      <td>Djibouti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>2002</td>\n",
       "      <td>NLD</td>\n",
       "      <td>﻿The smoke\\nat ground zero, only a few blocks ...</td>\n",
       "      <td>128</td>\n",
       "      <td>﻿the smoke\\nat ground zero only a few blocks a...</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "      <td>AGO</td>\n",
       "      <td>At the outset, \\nI would like to salute the in...</td>\n",
       "      <td>1</td>\n",
       "      <td>at the outset \\ni would like to salute the int...</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "      <td>AUT</td>\n",
       "      <td>Let me address at the \\noutset a burning issue...</td>\n",
       "      <td>9</td>\n",
       "      <td>let me address at the \\noutset a burning issue...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "      <td>MNE</td>\n",
       "      <td>Allow me,  Mr. President, to join others in w...</td>\n",
       "      <td>117</td>\n",
       "      <td>allow me  mr president to join others in welc...</td>\n",
       "      <td>Montenegro</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "      <td>FJI</td>\n",
       "      <td>On behalf of  the people of Fiji, I extend to ...</td>\n",
       "      <td>57</td>\n",
       "      <td>on behalf of  the people of fiji i extend to y...</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>62</td>\n",
       "      <td>2007</td>\n",
       "      <td>URY</td>\n",
       "      <td>I  wish to congratulate Mr. Srgjan Kerim on hi...</td>\n",
       "      <td>180</td>\n",
       "      <td>i  wish to congratulate mr srgjan kerim on his...</td>\n",
       "      <td>Uruguay</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1138 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      session  year country  \\\n",
       "0          57  2002     PAN   \n",
       "1          57  2002     IND   \n",
       "2          57  2002     MDV   \n",
       "3          57  2002     DJI   \n",
       "4          57  2002     NLD   \n",
       "...       ...   ...     ...   \n",
       "1133       62  2007     AGO   \n",
       "1134       62  2007     AUT   \n",
       "1135       62  2007     MNE   \n",
       "1136       62  2007     FJI   \n",
       "1137       62  2007     URY   \n",
       "\n",
       "                                                   text  label  \\\n",
       "0     ﻿Allow me\\nto begin my statement by expressing...    135   \n",
       "1     ﻿I\\ncongratulate Mr. Kavan on his election as ...     77   \n",
       "2     ﻿Mr. President, it gives\\nme great pleasure to...    110   \n",
       "3     ﻿In a year\\nof frightful tragedy and uncertain...     45   \n",
       "4     ﻿The smoke\\nat ground zero, only a few blocks ...    128   \n",
       "...                                                 ...    ...   \n",
       "1133  At the outset, \\nI would like to salute the in...      1   \n",
       "1134  Let me address at the \\noutset a burning issue...      9   \n",
       "1135   Allow me,  Mr. President, to join others in w...    117   \n",
       "1136  On behalf of  the people of Fiji, I extend to ...     57   \n",
       "1137  I  wish to congratulate Mr. Srgjan Kerim on hi...    180   \n",
       "\n",
       "                                         text_processed country_name  \\\n",
       "0     ﻿allow me\\nto begin my statement by expressing...       Panama   \n",
       "1     ﻿i\\ncongratulate mr kavan on his election as p...        India   \n",
       "2     ﻿mr president it gives\\nme great pleasure to j...     Maldives   \n",
       "3     ﻿in a year\\nof frightful tragedy and uncertain...     Djibouti   \n",
       "4     ﻿the smoke\\nat ground zero only a few blocks a...  Netherlands   \n",
       "...                                                 ...          ...   \n",
       "1133  at the outset \\ni would like to salute the int...       Angola   \n",
       "1134  let me address at the \\noutset a burning issue...      Austria   \n",
       "1135   allow me  mr president to join others in welc...   Montenegro   \n",
       "1136  on behalf of  the people of fiji i extend to y...         Fiji   \n",
       "1137  i  wish to congratulate mr srgjan kerim on his...      Uruguay   \n",
       "\n",
       "      coalition_of_willing  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        1  \n",
       "...                    ...  \n",
       "1133                     1  \n",
       "1134                     0  \n",
       "1135                     0  \n",
       "1136                     0  \n",
       "1137                     0  \n",
       "\n",
       "[1138 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.read_csv(\"UN_preprocessd_data.csv\")\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = articles[\"text_processed\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    015\n",
       "1                     02\n",
       "2                    020\n",
       "3                    033\n",
       "4                    039\n",
       "              ...       \n",
       "14873           ìfrozenî\n",
       "14874                ìin\n",
       "14875    ìresponsibility\n",
       "14876         ìstandards\n",
       "14877                ìwe\n",
       "Name: word, Length: 14878, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.5, min_df=2, stop_words=\"english\")\n",
    "# docs = torch.from_numpy(vectorizer.fit_transform(news[\"data\"]).toarray())\n",
    "docs = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "vocab = pd.DataFrame(columns=[\"word\", \"index\"])\n",
    "vocab[\"word\"] = vectorizer.get_feature_names_out()\n",
    "vocab[\"index\"] = vocab.index\n",
    "vocab[\"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size: 14878\n",
      "Corpus size: (1138, 14878)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dictionary size: %d\" % len(vocab))\n",
    "print(\"Corpus size: {}\".format(docs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_docs = articles[\"coalition_of_willing\"].values\n",
    "label_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save docs to file, format as non-zero count of columns, then followed by sum of word index and count\n",
    "with open(des_path + \"UN_kfold.dat\", \"w\") as f:\n",
    "    for i in range(len(docs)):\n",
    "        # number of non-zero columns for docs[i]\n",
    "        f.write(str(len(np.nonzero(docs[i])[0])) + \" \")\n",
    "        for j in range(len(vocab)):\n",
    "            if docs[i][j] > 0:\n",
    "                f.write(str(j) + \":\" + str(docs[i][j]) + \" \")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(des_path + \"label_UN_kfold.dat\", \"w\") as f:\n",
    "    for i in range(len(label_docs)):\n",
    "        # only write the label if it is not -1\n",
    "        if label_docs[i] != -1:\n",
    "            f.write(str(label_docs[i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ceate a function that can copy the lines from one file to another by a list of indices\n",
    "def copy_lines(file, indices, output):\n",
    "    with open(file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        with open(output, \"w\") as out:\n",
    "            for i in indices:\n",
    "                out.write(lines[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 910 228\n",
      "1 910 228\n",
      "2 910 228\n",
      "3 911 227\n",
      "4 911 227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# remove the -1 labels\n",
    "label_docs = label_docs[label_docs != -1]\n",
    "\n",
    "# split the data into 5 folds\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# initialize the fold label with all zeros\n",
    "kfold = np.zeros(len(label_docs))\n",
    "\n",
    "# create the folds for the data\n",
    "for i, (train_index, test_index) in enumerate(skf.split(texts, label_docs)):\n",
    "    copy_lines(\n",
    "        des_path + \"UN_kfold.dat\",\n",
    "        train_index,\n",
    "        des_path + \"UN_kfold_train_\" + str(i) + \".dat\",\n",
    "    )\n",
    "    copy_lines(\n",
    "        des_path + \"UN_kfold.dat\",\n",
    "        test_index,\n",
    "        des_path + \"UN_kfold_test_\" + str(i) + \".dat\",\n",
    "    )\n",
    "    copy_lines(\n",
    "        des_path + \"label_UN_kfold.dat\",\n",
    "        train_index,\n",
    "        des_path + \"label_UN_kfold_train_\" + str(i) + \".dat\",\n",
    "    )\n",
    "    copy_lines(\n",
    "        des_path + \"label_UN_kfold.dat\",\n",
    "        test_index,\n",
    "        des_path + \"label_UN_kfold_test_\" + str(i) + \".dat\",\n",
    "    )\n",
    "    print(i, len(train_index), len(test_index))\n",
    "    kfold[test_index] = i\n",
    "\n",
    "# save the fold label\n",
    "np.savetxt(des_path + \"UN_kfold_label.csv\", kfold, fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "def train_test(kfold):\n",
    "    accur = []\n",
    "    for k in range(kfold):\n",
    "        train_data = des_path + f\"UN_kfold_train_{k}.dat\"\n",
    "        train_label = des_path + f\"label_UN_kfold_train_{k}.dat\"\n",
    "        train_tmp = des_path + f\"UN_tmp_{k}\"\n",
    "        test_data = des_path + f\"UN_kfold_test_{k}.dat\"\n",
    "        test_label = des_path + f\"label_UN_kfold_test_{k}.dat\"\n",
    "        model_path = train_tmp + \"/final.model\"\n",
    "        test_tmp = des_path + f\"UN_tmp_inf_{k}\"\n",
    "        # run the following command in the terminal\n",
    "        subprocess.run(\n",
    "            f\"./slda est {train_data} {train_label} ./settings.txt 1.0 {num_topics} random {train_tmp}\",\n",
    "            shell=True,\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "        )\n",
    "        result = subprocess.run(\n",
    "            f\"./slda inf {test_data} {test_label} ./settings.txt {model_path} {test_tmp}\",\n",
    "            shell=True,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "        # Split the output into lines\n",
    "        output_lines = result.stdout.splitlines()\n",
    "\n",
    "        # Get the last line of the output\n",
    "        last_line = output_lines[-1] if output_lines else \"No output\"\n",
    "\n",
    "        # Extract the accuracy value from the last line\n",
    "        if \"average accuracy:\" in last_line:\n",
    "            accuracy = last_line.split(\"average accuracy:\")[1].strip()\n",
    "            print(f\"Fold {k} accuracy: {accuracy}\")\n",
    "            accur.append(float(accuracy))\n",
    "        else:\n",
    "            print(f\"Fold {k} failed\")\n",
    "\n",
    "    print(f\"Average accuracy: {np.mean(accur)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 accuracy: 0.741\n",
      "Fold 1 accuracy: 0.741\n",
      "Fold 2 accuracy: 0.741\n",
      "Fold 3 accuracy: 0.744\n",
      "Fold 4 accuracy: 0.744\n",
      "Average accuracy: 0.7421999999999999\n"
     ]
    }
   ],
   "source": [
    "train_test(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
